#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–∑ source_url –∏ —Å–æ–∑–¥–∞—ë—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""

import json
import sys
import os
from pathlib import Path
import requests
from bs4 import BeautifulSoup
import re

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
SCRIPT_DIR = Path(__file__).parent.absolute()
sys.path.insert(0, str(SCRIPT_DIR))

from create_title_from_content import —Å–æ–∑–¥–∞—Ç—å_–∑–∞–≥–æ–ª–æ–≤–æ–∫_–Ω–∞_–æ—Å–Ω–æ–≤–µ_–∫–æ–Ω—Ç–µ–Ω—Ç–∞

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏
if (SCRIPT_DIR.parent / 'public_html').exists():
    REPO_ROOT = SCRIPT_DIR.parent
elif (SCRIPT_DIR / 'public_html').exists():
    REPO_ROOT = SCRIPT_DIR
else:
    REPO_ROOT = Path.cwd()

BLOG_POSTS_FILE = REPO_ROOT / 'public_html' / 'blog-posts.json'

def –ø–æ–ª—É—á–∏—Ç—å_–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫(url):
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏ –∏–∑ source_url"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –î–ª—è skinnyms.com
        if 'skinnyms.com' in url:
            title_el = soup.select_one("h1.entry-title, h1.post-title, h1")
            if title_el:
                return title_el.get_text(strip=True)
        
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        selectors = [
            'h1.entry-title',
            'h1.post-title',
            'h1.article-title',
            'article h1',
            'h1',
            'meta[property="og:title"]'
        ]
        
        for selector in selectors:
            el = soup.select_one(selector)
            if el:
                if selector.startswith('meta'):
                    return el.get('content', '').strip()
                else:
                    return el.get_text(strip=True)
        
        og_title = soup.find('meta', property='og:title')
        if og_title and og_title.get('content'):
            return og_title['content'].strip()
        
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–∑ {url}: {e}")
        return None

def –æ–±–Ω–æ–≤–∏—Ç—å_–∑–∞–≥–æ–ª–æ–≤–∫–∏_—Å—Ç–∞—Ç–µ–π():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π"""
    # –°–∫–∞—á–∏–≤–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å —Å–∞–π—Ç–∞
    print("üì• –°–∫–∞—á–∏–≤–∞—é blog-posts.json —Å —Å–∞–π—Ç–∞...")
    try:
        response = requests.get("https://www.tabatatimer.ru/blog-posts.json", timeout=30)
        response.raise_for_status()
        data = json.loads(response.text)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
        if BLOG_POSTS_FILE.exists():
            print("üìÇ –ò—Å–ø–æ–ª—å–∑—É—é –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª...")
            with open(BLOG_POSTS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É")
            return
    
    posts = data.get('posts', [])
    print(f"üìä –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {len(posts)}")
    
    # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
    problem_slugs = [
        'muzhskoy-zhkt-chto-nuzhno-znat-i-kak-zaschitit-kis',
        'gotov-k-lyubomu-vyzovu-programma-trenirovok',
        'poleznaya-statya-o-fitnese-i-zdorove'
    ]
    
    –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ = 0
    for post in posts:
        url = post.get('url', '')
        if not url:
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–Ω–æ–π —Å—Ç–∞—Ç—å—ë–π
        current_title = post.get('title', '').lower()
        is_problem = (
            any(slug in url for slug in problem_slugs) or
            '–º—É–∂—Å–∫–æ–π –∂–∫—Ç' in current_title or
            '–≥–æ—Ç–æ–≤ –∫ –ª—é–±–æ–º—É –≤—ã–∑–æ–≤—É' in current_title or
            '–ø–æ–ª–µ–∑–Ω–∞—è —Å—Ç–∞—Ç—å—è –æ —Ñ–∏—Ç–Ω–µ—Å–µ' in current_title
        )
        if not is_problem:
            continue
        
        source_url = post.get('source_url', '')
        if not source_url:
            print(f"‚ö†Ô∏è –ù–µ—Ç source_url –¥–ª—è {url}")
            continue
        
        print(f"\nüîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {url}")
        print(f"   Source URL: {source_url}")
        print(f"   –¢–µ–∫—É—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: {post.get('title', 'N/A')}")
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫ = –ø–æ–ª—É—á–∏—Ç—å_–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫(source_url)
        
        if not –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫:
            print(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫")
            continue
        
        # –û—á–∏—â–∞–µ–º –æ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫ = re.sub(r'podcast\s*#?\s*\d+[,:]?\s*', '', –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫, flags=re.IGNORECASE)
        –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫ = re.sub(r'episode\s*#?\s*\d+[,:]?\s*', '', –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫, flags=re.IGNORECASE)
        –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫ = re.sub(r'#\s*\d+[,:]?\s*', '', –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫)
        –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫ = –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫.strip(' -‚Äî:')
        
        print(f"   ‚úÖ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: {–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫}")
        
        # –°–æ–∑–¥–∞—ë–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        –∫–æ–Ω—Ç–µ–Ω—Ç = post.get('text', '')
        if not –∫–æ–Ω—Ç–µ–Ω—Ç:
            print(f"   ‚ö†Ô∏è –ù–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫")
            –Ω–æ–≤—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫ = –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫
        else:
            print(f"   ü§ñ –°–æ–∑–¥–∞—é –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ DeepSeek...")
            –Ω–æ–≤—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫ = —Å–æ–∑–¥–∞—Ç—å_–∑–∞–≥–æ–ª–æ–≤–æ–∫_–Ω–∞_–æ—Å–Ω–æ–≤–µ_–∫–æ–Ω—Ç–µ–Ω—Ç–∞(–∫–æ–Ω—Ç–µ–Ω—Ç, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫)
            print(f"   ‚úÖ –ù–æ–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: {–Ω–æ–≤—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫}")
        
        post['title'] = –Ω–æ–≤—ã–π_–∑–∞–≥–æ–ª–æ–≤–æ–∫
        –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ += 1
        print(f"   ‚úÖ –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ–±–Ω–æ–≤–ª—ë–Ω!")
    
    if –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ > 0:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Ñ–∞–π–ª
        with open(BLOG_POSTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\n‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ}")
        print(f"üìù –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {BLOG_POSTS_FILE}")
        
        # –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        print(f"\nüìÑ –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É—é HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
        try:
            from generate_blog_post_page import —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å_—Å—Ç—Ä–∞–Ω–∏—Ü—ã_–¥–ª—è_–≤—Å–µ—Ö_–ø–æ—Å—Ç–æ–≤
            —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å_—Å—Ç—Ä–∞–Ω–∏—Ü—ã_–¥–ª—è_–≤—Å–µ—Ö_–ø–æ—Å—Ç–æ–≤()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ HTML: {e}")
    else:
        print("\n‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è")

if __name__ == '__main__':
    –æ–±–Ω–æ–≤–∏—Ç—å_–∑–∞–≥–æ–ª–æ–≤–∫–∏_—Å—Ç–∞—Ç–µ–π()
