#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–µ—Ä –∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö —Ü–µ–Ω ProShoper.ru (–ü—è—Ç—ë—Ä–æ—á–∫–∞, –ú–æ—Å–∫–≤–∞)

–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:
- requests + BeautifulSoup4 (–±–µ–∑ Selenium)
- —Å—Ç–∞—Ç–∏—á–Ω—ã–π HTML-–ø–∞—Ä—Å–∏–Ω–≥

–í—ã—Ö–æ–¥:
- grocery_prices.json (—Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ —Å —Ü–µ–Ω–∞–º–∏)

–í–ê–ñ–ù–û:
- –°–∫—Ä–∏–ø—Ç —É—Å—Ç–æ–π—á–∏–≤ –∫ –æ—à–∏–±–∫–∞–º (–µ—Å–ª–∏ —Å–∞–π—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –Ω–µ –ª–æ–º–∞–µ–º –¥–∞–Ω–Ω—ã–µ).
- –í—Å–µ –ª–æ–≥–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""

from __future__ import annotations

import json
import random
import re
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# requests / bs4 –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ ‚Äî graceful degradation
try:
    import requests

    REQUESTS_AVAILABLE = True
except ImportError:
    requests = None
    REQUESTS_AVAILABLE = False
    print("‚ö†Ô∏è requests –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∫–ª—é—á—ë–Ω (graceful —Ä–µ–∂–∏–º).")

try:
    from bs4 import BeautifulSoup

    BS4_AVAILABLE = True
except ImportError:
    BeautifulSoup = None
    BS4_AVAILABLE = False
    print("‚ö†Ô∏è beautifulsoup4 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∫–ª—é—á—ë–Ω (graceful —Ä–µ–∂–∏–º).")


# –ü–∞—Ä—Å–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å ProShoper.ru (–≤ –ø—Ä–æ–º–ø—Ç–µ URL –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å)
CATEGORIES = {
    "–§—Ä—É–∫—Ç—ã, –æ–≤–æ—â–∏, –∑–µ–ª–µ–Ω—å": "https://proshoper.ru/actions/pyaterochka/moskva/",
    "–ú–æ–ª–æ–∫–æ, —Å—ã—Ä, —è–π—Ü–∞": "https://proshoper.ru/actions/pyaterochka/moskva/",
    "–ú—è—Å–æ, —Ä—ã–±–∞, –∫–æ–ª–±–∞—Å—ã": "https://proshoper.ru/actions/pyaterochka/moskva/",
}

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )
}

OUT_FILE = Path("grocery_prices.json")


def _parse_price(text: str) -> Optional[float]:
    """–û—á–∏—â–∞–µ—Ç —Ü–µ–Ω—É –≤–∏–¥–∞ '139.99 ‚ÇΩ' / '139,99 ‚ÇΩ' ‚Üí 139.99"""
    if not text:
        return None
    s = text.replace("\xa0", " ").strip()
    s = s.replace("‚ÇΩ", "").replace("—Ä—É–±.", "").replace("—Ä—É–±", "").strip()
    s = s.replace(" ", "")
    s = s.replace(",", ".")
    m = re.search(r"(\d+(?:\.\d+)?)", s)
    return float(m.group(1)) if m else None


def _guess_unit(name: str) -> str:
    """
    –ü—Ä–∏–º–∏—Ç–∏–≤–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è.
    –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ '–∫–≥' ‚Äî —Å—á–∏—Ç–∞–µ–º –∫–≥, –∏–Ω–∞—á–µ —à—Ç.
    """
    s = (name or "").lower()
    if "–∫–≥" in s:
        return "–∫–≥"
    return "—à—Ç"


def _calc_discount(price: Optional[float], old_price: Optional[float]) -> Optional[str]:
    if price is None or old_price is None or old_price <= 0:
        return None
    d = round((old_price - price) / old_price * 100)
    return f"{d}%" if d != 0 else "0%"


def _fetch_html(url: str) -> Optional[str]:
    if not REQUESTS_AVAILABLE:
        return None
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        resp.raise_for_status()
        return resp.text
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
        return None


def _parse_products_from_html(html: str, category: str) -> List[Dict[str, Any]]:
    if not BS4_AVAILABLE or not html:
        return []

    soup = BeautifulSoup(html, "lxml")
    products: List[Dict[str, Any]] = []

    # ProShoper —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–æ—Ä–∏–µ–Ω—Ç–∏—Ä –∏–∑ –ø—Ä–æ–º–ø—Ç–∞):
    # <article id="id_product_XXX">
    #   <div class="price_new">139.99 ‚ÇΩ</div>
    #   <div class="price_old">159.99 ‚ÇΩ</div>
    #   <div class="name">–Ø–±–ª–æ–∫–∏ ...</div>
    # </article>
    for article in soup.find_all("article"):
        try:
            name_el = article.find(class_="name")
            price_el = article.find(class_="price_new")
            old_el = article.find(class_="price_old")

            name = (name_el.get_text(" ", strip=True) if name_el else "").strip()
            if not name:
                continue

            price = _parse_price(price_el.get_text(" ", strip=True) if price_el else "")
            old_price = _parse_price(old_el.get_text(" ", strip=True) if old_el else "")
            discount = _calc_discount(price, old_price)
            unit = _guess_unit(name)

            if price is None:
                # –±–µ–∑ –Ω–æ–≤–æ–π —Ü–µ–Ω—ã —Ç–æ–≤–∞—Ä –±–µ—Å–ø–æ–ª–µ–∑–µ–Ω
                continue

            products.append(
                {
                    "name": name,
                    "category": category,
                    "price": price,
                    "old_price": old_price,
                    "discount": discount,
                    "unit": unit,
                }
            )
        except Exception:
            # –Ω–µ –ª–æ–º–∞–µ–º—Å—è –∏–∑-–∑–∞ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
            continue

    return products


def _load_existing() -> Dict[str, Any]:
    if OUT_FILE.exists():
        try:
            return json.loads(OUT_FILE.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}


def _save(data: Dict[str, Any]) -> None:
    OUT_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


def main() -> int:
    print("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ ProShoper.ru...")

    existing = _load_existing()

    if not (REQUESTS_AVAILABLE and BS4_AVAILABLE):
        # graceful: –Ω–µ –ø–æ—Ä—Ç–∏–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        if not OUT_FILE.exists():
            data = {
                "last_updated": datetime.now().strftime("%Y-%m-%dT%H:%M:%S"),
                "source": "ProShoper.ru",
                "store": "–ü—è—Ç—ë—Ä–æ—á–∫–∞",
                "city": "–ú–æ—Å–∫–≤–∞",
                "products": [],
            }
            _save(data)
            print("üíæ –°–æ–∑–¥–∞–Ω –ø—É—Å—Ç–æ–π grocery_prices.json (graceful —Ä–µ–∂–∏–º)")
        else:
            print("‚ö†Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–ø—É—â–µ–Ω (–Ω–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π). –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–µ–Ω—ã.")
        return 0

    all_products: List[Dict[str, Any]] = []

    for cat, url in CATEGORIES.items():
        print(f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {cat}")
        html = _fetch_html(url)
        if not html:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {cat}")
            continue

        products = _parse_products_from_html(html, cat)
        print(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
        all_products.extend(products)

        # –ó–∞–¥–µ—Ä–∂–∫–∞ 1‚Äì2 —Å–µ–∫ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time.sleep(1 + random.random())

    if not all_products:
        print("‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –û—Å—Ç–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.")
        return 0

    data = {
        "last_updated": datetime.now().strftime("%Y-%m-%dT%H:%M:%S"),
        "source": "ProShoper.ru",
        "store": "–ü—è—Ç—ë—Ä–æ—á–∫–∞",
        "city": "–ú–æ—Å–∫–≤–∞",
        "products": all_products,
    }

    _save(data)
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ grocery_prices.json")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


