#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
    –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
    
    Senior-level —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è:
    - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤
    - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å GitHub Actions
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import requests

class AutonomousMonitor:
    """–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.monitoring_data = {
            'last_check': None,
            'errors_found': [],
            'fixes_applied': [],
            'system_status': 'unknown'
        }
    
    def check_workflow_status(self) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å GitHub Actions workflows —á–µ—Ä–µ–∑ API"""
        status = {
            'workflows': [],
            'failed_runs': [],
            'errors': [],
            'status': 'unknown'
        }
        
        github_token = os.getenv('GITHUB_TOKEN')
        repo = os.getenv('GITHUB_REPOSITORY', 'VR-Lounge/fitness-timer-autopost')
        
        if not github_token:
            status['errors'].append("GITHUB_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return status
        
        try:
            import requests
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ workflows
            workflows_url = f"https://api.github.com/repos/{repo}/actions/workflows"
            headers = {
                "Authorization": f"token {github_token}",
                "Accept": "application/vnd.github.v3+json"
            }
            
            response = requests.get(workflows_url, headers=headers, timeout=10)
            if response.status_code == 200:
                workflows_data = response.json()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—É—Å–∫–∏ –∫–∞–∂–¥–æ–≥–æ workflow
                important_workflows = [
                    'womenshealth-parser.yml',
                    'menshealth-parser.yml',
                    'autonomous-monitoring.yml'
                ]
                
                for workflow in workflows_data.get('workflows', []):
                    workflow_name = workflow.get('name', '')
                    workflow_path = workflow.get('path', '')
                    
                    if any(important in workflow_path for important in important_workflows):
                        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—É—Å–∫–∏
                        runs_url = f"https://api.github.com/repos/{repo}/actions/workflows/{workflow['id']}/runs?per_page=3"
                        runs_response = requests.get(runs_url, headers=headers, timeout=10)
                        
                        if runs_response.status_code == 200:
                            runs_data = runs_response.json()
                            for run in runs_data.get('workflow_runs', []):
                                run_status = run.get('status')
                                conclusion = run.get('conclusion')
                                
                                if conclusion == 'failure':
                                    status['failed_runs'].append({
                                        'workflow': workflow_name,
                                        'run_id': run.get('id'),
                                        'created_at': run.get('created_at'),
                                        'html_url': run.get('html_url')
                                    })
                                
                                status['workflows'].append({
                                    'name': workflow_name,
                                    'status': run_status,
                                    'conclusion': conclusion,
                                    'created_at': run.get('created_at')
                                })
                
                if status['failed_runs']:
                    status['status'] = 'error'
                else:
                    status['status'] = 'ok'
            else:
                status['errors'].append(f"–û—à–∏–±–∫–∞ API GitHub: {response.status_code}")
                status['status'] = 'error'
                
        except Exception as e:
            status['errors'].append(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ workflows: {e}")
            status['status'] = 'error'
        
        return status
    
    def check_parser_status(self) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–±–æ–∏—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤ (Men's Health –∏ Women's Health)"""
        status = {
            'menshealth': {
                'last_run': None,
                'articles_processed': 0,
                'errors': [],
                'status': 'unknown'
            },
            'womenshealth': {
                'last_run': None,
                'articles_processed': 0,
                'errors': [],
                'status': 'unknown'
            },
            'overall_status': 'unknown'
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Men's Health –ø–∞—Ä—Å–µ—Ä
        menshealth_file = self.project_root / '.menshealth_processed.json'
        if menshealth_file.exists():
            try:
                with open(menshealth_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    status['menshealth']['last_run'] = data.get('last_update')
                    status['menshealth']['articles_processed'] = len(data.get('articles', []))
                    status['menshealth']['status'] = 'active'
            except Exception as e:
                status['menshealth']['errors'].append(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
                status['menshealth']['status'] = 'error'
        else:
            status['menshealth']['status'] = 'not_started'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Women's Health –ø–∞—Ä—Å–µ—Ä
        womenshealth_file = self.project_root / '.womenshealth_processed.json'
        if womenshealth_file.exists():
            try:
                with open(womenshealth_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    status['womenshealth']['last_run'] = data.get('last_update')
                    status['womenshealth']['articles_processed'] = len(data.get('articles', []))
                    status['womenshealth']['status'] = 'active'
            except Exception as e:
                status['womenshealth']['errors'].append(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
                status['womenshealth']['status'] = 'error'
        else:
            status['womenshealth']['status'] = 'not_started'
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        if status['menshealth']['status'] == 'error' or status['womenshealth']['status'] == 'error':
            status['overall_status'] = 'error'
        elif status['menshealth']['status'] == 'active' and status['womenshealth']['status'] == 'active':
            status['overall_status'] = 'ok'
        else:
            status['overall_status'] = 'warning'
        
        return status
    
    def auto_fix_common_issues(self) -> List[str]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        fixes_applied = []
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤
        python_files = list(self.project_root.glob('*.py'))
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    original_content = content
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–µ—Ä–æ–≤
                if 'parser' in py_file.name:
                    required_imports = {
                        'menshealth_parser': ['from bs4 import BeautifulSoup', 'import requests', 'import json'],
                        'womenshealth_parser': ['from bs4 import BeautifulSoup', 'import requests', 'import json']
                    }
                    
                    for parser_type, imports in required_imports.items():
                        if parser_type in py_file.name:
                            for imp in imports:
                                if imp not in content:
                                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∏–º–ø–æ—Ä—Ç
                                    lines = content.split('\n')
                                    last_import = 0
                                    for i, line in enumerate(lines):
                                        if line.strip().startswith('import ') or line.strip().startswith('from '):
                                            last_import = i
                                    
                                    lines.insert(last_import + 1, imp)
                                    content = '\n'.join(lines)
                                    fixes_applied.append(f"–î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç {imp} –≤ {py_file.name}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
                if 'os.getenv' in content or 'os.environ' in content:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                    if 'TELEGRAM_BOT_TOKEN' in content and 'if not' not in content.split('TELEGRAM_BOT_TOKEN')[0][-50:]:
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –≤ –Ω–∞—á–∞–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ main/–≥–ª–∞–≤–Ω–∞—è
                        if 'def –≥–ª–∞–≤–Ω–∞—è(' in content or 'def main(' in content:
                            lines = content.split('\n')
                            for i, line in enumerate(lines):
                                if 'def –≥–ª–∞–≤–Ω–∞—è(' in line or 'def main(' in line:
                                    # –ò—â–µ–º –Ω–∞—á–∞–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏
                                    indent = len(line) - len(line.lstrip())
                                    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø–æ—Å–ª–µ docstring
                                    j = i + 1
                                    while j < len(lines) and (lines[j].strip().startswith('"""') or lines[j].strip().startswith("'''") or not lines[j].strip()):
                                        j += 1
                                    if j < len(lines):
                                        check_code = f"{' ' * (indent + 4)}if not os.getenv('TELEGRAM_BOT_TOKEN'):\n{' ' * (indent + 8)}print('‚ö†Ô∏è TELEGRAM_BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω')"
                                        lines.insert(j, check_code)
                                        content = '\n'.join(lines)
                                        fixes_applied.append(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ {py_file.name}")
                                        break
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                if content != original_content:
                    with open(py_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                        
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {py_file}: {e}")
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ requirements.txt
        req_file = self.project_root / 'requirements.txt'
        if req_file.exists():
            with open(req_file, 'r', encoding='utf-8') as f:
                requirements = f.read()
            
            required_packages = ['beautifulsoup4', 'lxml', 'requests', 'scikit-learn']
            missing = []
            for package in required_packages:
                if package not in requirements and package.replace('-', '_') not in requirements:
                    missing.append(package)
            
            if missing:
                with open(req_file, 'a', encoding='utf-8') as f:
                    for package in missing:
                        f.write(f"\n{package}")
                fixes_applied.append(f"–î–æ–±–∞–≤–ª–µ–Ω—ã –ø–∞–∫–µ—Ç—ã –≤ requirements.txt: {', '.join(missing)}")
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_files = {
            '.lighthouserc.json': '{}',
            '.gitignore': '.womenshealth_processed.json\n.menshealth_processed.json\n.content_hashes.json\n'
        }
        
        for config_file, default_content in config_files.items():
            config_path = self.project_root / config_file
            if not config_path.exists():
                with open(config_path, 'w', encoding='utf-8') as f:
                    f.write(default_content)
                fixes_applied.append(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config_file}")
        
        return fixes_applied
    
    def send_telegram_notification(self, message: str, is_critical: bool = False):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω—É –≤ –ª–∏—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è)"""
        bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        # –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ ADMIN_TELEGRAM_CHAT_ID –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
        chat_id = os.getenv('ADMIN_TELEGRAM_CHAT_ID')
        
        if not bot_token:
            print("‚ö†Ô∏è TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return False
        
        if not chat_id:
            print("‚ö†Ô∏è ADMIN_TELEGRAM_CHAT_ID –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
            return False
        
        try:
            url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
            emoji = "üö®" if is_critical else "‚ö†Ô∏è"
            text = f"{emoji} **–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**\n\n{message}"
            
            payload = {
                'chat_id': chat_id,
                'text': text,
                'parse_mode': 'Markdown'
            }
            
            response = requests.post(url, json=payload, timeout=10)
            return response.status_code == 200
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")
            return False
    
    def generate_monitoring_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ"""
        parser_status = self.check_parser_status()
        workflow_status = self.check_workflow_status()
        fixes = self.auto_fix_common_issues()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
        critical_errors = []
        if parser_status['overall_status'] == 'error':
            critical_errors.append("‚ùå –û—à–∏–±–∫–∏ –≤ —Ä–∞–±–æ—Ç–µ –ø–∞—Ä—Å–µ—Ä–æ–≤")
        if workflow_status['status'] == 'error' and workflow_status['failed_runs']:
            critical_errors.append(f"‚ùå –£–ø–∞–≤—à–∏–µ workflows: {len(workflow_status['failed_runs'])}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö
        if critical_errors:
            notification = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:\n\n" + "\n".join(critical_errors)
            self.send_telegram_notification(notification, is_critical=True)
        
        report = f"""
# üìä –û–¢–ß–Å–¢ –ê–í–¢–û–ù–û–ú–ù–û–ì–û –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê

**–í—Ä–µ–º—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üîç –°—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–µ—Ä–æ–≤

### Men's Health:
- **–°—Ç–∞—Ç—É—Å:** {parser_status['menshealth']['status']}
- **–ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—É—Å–∫:** {parser_status['menshealth']['last_run'] or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}
- **–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç–∞—Ç–µ–π:** {parser_status['menshealth']['articles_processed']}
- **–û—à–∏–±–∫–∏:** {len(parser_status['menshealth']['errors'])}

### Women's Health:
- **–°—Ç–∞—Ç—É—Å:** {parser_status['womenshealth']['status']}
- **–ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—É—Å–∫:** {parser_status['womenshealth']['last_run'] or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}
- **–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç–∞—Ç–µ–π:** {parser_status['womenshealth']['articles_processed']}
- **–û—à–∏–±–∫–∏:** {len(parser_status['womenshealth']['errors'])}

### –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å: {parser_status['overall_status']}

## üîÑ –°—Ç–∞—Ç—É—Å GitHub Actions Workflows

- **–°—Ç–∞—Ç—É—Å:** {workflow_status['status']}
- **–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ workflows:** {len(workflow_status['workflows'])}
- **–£–ø–∞–≤—à–∏—Ö –∑–∞–ø—É—Å–∫–æ–≤:** {len(workflow_status['failed_runs'])}

"""
        
        if workflow_status['failed_runs']:
            report += "\n### –£–ø–∞–≤—à–∏–µ workflows:\n"
            for failed in workflow_status['failed_runs'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                report += f"- ‚ùå {failed['workflow']} (ID: {failed['run_id']})\n"
        
        report += f"""
## üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(fixes)}
"""
        
        if fixes:
            report += "\n### –ü—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:\n"
            for fix in fixes:
                report += f"- ‚úÖ {fix}\n"
        else:
            report += "\n‚úÖ –ü—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\n"
        
        if parser_status['menshealth']['errors']:
            report += "\n### –û—à–∏–±–∫–∏ Men's Health:\n"
            for error in parser_status['menshealth']['errors']:
                report += f"- ‚ùå {error}\n"
        
        if parser_status['womenshealth']['errors']:
            report += "\n### –û—à–∏–±–∫–∏ Women's Health:\n"
            for error in parser_status['womenshealth']['errors']:
                report += f"- ‚ùå {error}\n"
        
        if workflow_status['errors']:
            report += "\n### –û—à–∏–±–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ workflows:\n"
            for error in workflow_status['errors']:
                report += f"- ‚ùå {error}\n"
        
        return report
    
    def save_report(self, report: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç"""
        report_file = self.project_root / f"monitoring_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_file}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    project_root = Path(__file__).parent
    monitor = AutonomousMonitor(project_root)
    
    print("üîç –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞—Ä—Å–µ—Ä–æ–≤
    parser_status = monitor.check_parser_status()
    print(f"üìä –°—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–µ—Ä–æ–≤: {parser_status['overall_status']}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ workflows
    workflow_status = monitor.check_workflow_status()
    print(f"üîÑ –°—Ç–∞—Ç—É—Å workflows: {workflow_status['status']}")
    if workflow_status['failed_runs']:
        print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É–ø–∞–≤—à–∏—Ö –∑–∞–ø—É—Å–∫–æ–≤: {len(workflow_status['failed_runs'])}")
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    fixes = monitor.auto_fix_common_issues()
    if fixes:
        print(f"‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(fixes)}")
        for fix in fixes:
            print(f"  - {fix}")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report = monitor.generate_monitoring_report()
    print("\n" + report)
    monitor.save_report(report)
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ –∫—Ä–∞—Ç–∫–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ
    if parser_status['overall_status'] == 'ok' and workflow_status['status'] == 'ok':
        monitor.send_telegram_notification(
            f"‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ\n\n"
            f"–ü–∞—Ä—Å–µ—Ä—ã: {parser_status['menshealth']['articles_processed'] + parser_status['womenshealth']['articles_processed']} —Å—Ç–∞—Ç–µ–π\n"
            f"Workflows: {len(workflow_status['workflows'])} –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ\n"
            f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(fixes)}",
            is_critical=False
        )

if __name__ == '__main__':
    main()
