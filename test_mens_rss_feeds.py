#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º—É–∂—Å–∫–∏—Ö RSS —Ñ–∏–¥–æ–≤
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å RSS –∫–∞–Ω–∞–ª–æ–≤
"""

import requests
import xml.etree.ElementTree as ET
from urllib.parse import urlparse
import time

# –ù–æ–≤—ã–µ –º—É–∂—Å–∫–∏–µ RSS —Ñ–∏–¥—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
NEW_MENS_RSS_FEEDS = [
    # –¢–û–ü-–ü–†–ò–û–†–ò–¢–ï–¢
    ("Men's Health (USA)", "https://www.menshealth.com/rss/fitness.xml"),
    ("Muscle & Fitness", "https://www.muscleandfitness.com/feed/"),
    ("Muscle & Strength", "https://www.muscleandstrength.com/rss.xml"),
    ("Nerd Fitness", "https://www.nerdfitness.com/feed/"),
    ("BarBend", "https://barbend.com/feed/"),
    
    # HIIT, TABATA, EMOM, AMRAP
    ("HIIT Science", "https://hiitscience.com/feed"),
    ("Men's Fitness", "https://www.mensfitness.com/.rss/feed/5a4c1162-86c8-4b99-8611-d683873db65d.xml"),
    ("Ross Training", "https://rosstraining.com/blog/feed/"),
    
    # –°–ò–õ–û–í–´–ï –¢–†–ï–ù–ò–†–û–í–ö–ò
    ("StrongFirst", "https://strongfirst.com/blog/feed"),
    ("Starting Strength", "https://startingstrength.com/rss.rss"),
    ("Breaking Muscle", "https://breakingmuscle.com/feed/"),
    ("Tony Gentilcore", "https://tonygentilcore.com/feed/"),
    ("Dr. John Rusin", "https://drjohnrusin.com/feed/"),
    ("Volt Athletics Blog", "https://feeds.feedburner.com/volt-blog"),
    
    # –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–´–ô –§–ò–¢–ù–ï–°
    ("Fit Dad Chris", "https://fitdadchris.com/feed/"),
    ("Hard To Kill Fitness", "https://hardtokillfitness.co/blogs/fitness-articles.atom"),
    ("Train Heroic", "https://www.trainheroic.com/feed/"),
    ("Simpli Faster", "https://simplifaster.com/articles/category/blog/feed/"),
    
    # –ü–ò–¢–ê–ù–ò–ï + –ë–ò–û–•–ê–ö–ò–ù–ì
    ("Ben Greenfield Life", "https://bengreenfieldlife.com/article/feed/"),
    ("Born Fitness", "https://www.bornfitness.com/feed/"),
    
    # –ö–û–ú–¨–Æ–ù–ò–¢–ò + –õ–ê–ô–§–°–¢–ê–ô–õ
    ("MensFitClub.com", "https://www.mensfitclub.com/mens-fitness/feed/"),
    ("Active Man", "https://activeman.com/category/health-fitness/feed/"),
    ("Zen Habits", "https://zenhabits.net/feed/"),
    ("Dai Manuel", "https://www.daimanuel.com/feed"),
    
    # –°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï
    ("Focus Fitness", "https://www.focusfitness.in/feed/"),
]

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–º—É–∂—Å–∫–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è)
RELEVANT_KEYWORDS = [
    'tabata', 'hiit', 'emom', 'amrap', 'interval', 'circuit', 'workout',
    'strength training', 'muscle building', 'workout for men', 'dad fitness',
    'testosterone', 'protein', 'fat loss', 'six pack', 'functional fitness',
    'crossfit', 'bodybuilding', 'powerlifting', 'weightlifting', 'training',
    'exercise', 'fitness', 'nutrition', 'diet', 'supplements', 'recovery',
    'men health', 'male fitness', 'gym', 'training program', 'workout plan'
]

def test_rss_feed(name, url):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç RSS —Ñ–∏–¥ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"""
    print(f"\n{'='*60}")
    print(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {name}")
    print(f"URL: {url}")
    print(f"{'='*60}")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            print(f"‚ùå –û—à–∏–±–∫–∞: HTTP {response.status_code}")
            return False, None
        
        # –ü–∞—Ä—Å–∏–º XML
        try:
            root = ET.fromstring(response.content)
        except ET.ParseError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
            return False, None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        items = []
        if root.tag.endswith('feed'):  # Atom
            items = root.findall('.//{http://www.w3.org/2005/Atom}entry')
        elif root.tag == 'rss':  # RSS 2.0
            channel = root.find('channel')
            if channel is not None:
                items = channel.findall('item')
        
        if not items:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –≤ —Ñ–∏–¥–µ")
            return False, None
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(items)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç–∞—Ç–µ–π)
        relevant_count = 0
        sample_titles = []
        
        for item in items[:5]:
            title = ''
            description = ''
            
            if item.tag.endswith('entry'):  # Atom
                title_elem = item.find('.//{http://www.w3.org/2005/Atom}title')
                summary_elem = item.find('.//{http://www.w3.org/2005/Atom}summary')
                if title_elem is not None:
                    title = title_elem.text or ''
                if summary_elem is not None:
                    description = summary_elem.text or ''
            else:  # RSS 2.0
                title_elem = item.find('title')
                desc_elem = item.find('description')
                if title_elem is not None:
                    title = title_elem.text or ''
                if desc_elem is not None:
                    description = desc_elem.text or ''
            
            text = (title + ' ' + description).lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            is_relevant = any(keyword in text for keyword in RELEVANT_KEYWORDS)
            
            if is_relevant:
                relevant_count += 1
                sample_titles.append(title[:60])
        
        relevance_percent = (relevant_count / min(5, len(items))) * 100
        print(f"‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevant_count}/{min(5, len(items))} —Å—Ç–∞—Ç–µ–π ({relevance_percent:.0f}%)")
        
        if sample_titles:
            print(f"üìù –ü—Ä–∏–º–µ—Ä—ã —Å—Ç–∞—Ç–µ–π:")
            for t in sample_titles[:3]:
                print(f"   - {t}")
        
        # –°—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º, –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã 40% —Å—Ç–∞—Ç–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
        is_relevant = relevance_percent >= 40
        
        return is_relevant, {
            'name': name,
            'url': url,
            'articles_count': len(items),
            'relevance': relevance_percent
        }
        
    except requests.exceptions.Timeout:
        print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ")
        return False, None
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return False, None
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return False, None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("="*60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–£–ñ–°–ö–ò–• RSS –§–ò–î–û–í")
    print("="*60)
    
    working_feeds = []
    failed_feeds = []
    
    for name, url in NEW_MENS_RSS_FEEDS:
        is_working, info = test_rss_feed(name, url)
        
        if is_working and info:
            working_feeds.append(info)
        else:
            failed_feeds.append((name, url))
        
        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time.sleep(1)
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "="*60)
    print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("="*60)
    print(f"\n‚úÖ –†–∞–±–æ—á–∏—Ö —Ñ–∏–¥–æ–≤: {len(working_feeds)}")
    print(f"‚ùå –ù–µ —Ä–∞–±–æ—á–∏—Ö —Ñ–∏–¥–æ–≤: {len(failed_feeds)}")
    
    if working_feeds:
        print("\nüìã –†–ê–ë–û–ß–ò–ï –§–ò–î–´ (–¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ø–∞—Ä—Å–µ—Ä):")
        print("\nMENSHEALTH_RSS_FEEDS = [")
        for feed in sorted(working_feeds, key=lambda x: x['relevance'], reverse=True):
            print(f"    # {feed['name']} ({feed['relevance']:.0f}% —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å, {feed['articles_count']} —Å—Ç–∞—Ç–µ–π)")
            print(f"    '{feed['url']}',")
        print("]")
    
    if failed_feeds:
        print("\n‚ùå –ù–ï –†–ê–ë–û–¢–ê–Æ–©–ò–ï –§–ò–î–´:")
        for name, url in failed_feeds:
            print(f"   - {name}: {url}")

if __name__ == '__main__':
    main()
