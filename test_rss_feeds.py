#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è RSS —Ñ–∏–¥–æ–≤
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å RSS –∫–∞–Ω–∞–ª–æ–≤
"""

import requests
import xml.etree.ElementTree as ET
from urllib.parse import urlparse
import time

# –ù–æ–≤—ã–µ RSS —Ñ–∏–¥—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
NEW_RSS_FEEDS = [
    # –¢–û–ü-–ü–†–ò–û–†–ò–¢–ï–¢
    ("Love Sweat Fitness", "https://lovesweatfitness.com/blogs/news.atom"),
    ("Blogilates", "https://www.blogilates.com/feed/"),
    ("Skinny Ms", "https://skinnyms.com/category/fitness/feed/"),
    ("Get Healthy U", "https://gethealthyu.com/feed/"),
    ("MyFitnessPal Blog", "https://blog.myfitnesspal.com/feed/"),
    ("Natalie Jill Fitness", "https://www.nataliejillfitness.com/feed/"),
    ("Steph Gaudreau", "https://www.stephgaudreau.com/feed/"),
    
    # –°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï
    ("FIT4MOM", "https://fit4mom.com/blog?format=rss"),
    ("Elly McGuinness", "https://ellymcguinness.com/feed/"),
    ("Laura London Fitness", "https://lauralondonfitness.com/feed/"),
    ("keep it simpElle", "https://www.keepitsimpelle.com/feed/"),
    ("Fit Girl's Diary", "https://fitgirlsdiary.com/feed/"),
    ("Massy Arias", "https://www.massyarias.com/feed/"),
    ("Carly Rowena", "https://www.carlyrowena.com/blog?format=rss"),
    ("Powercakes", "https://www.powercakes.net/feed/"),
    
    # –ü–ò–¢–ê–ù–ò–ï + WELLNESS
    ("Healthifyme", "https://www.healthifyme.com/blog/feed/"),
    ("Be Healthy Now", "https://www.behealthynow.co.uk/feed/"),
    ("Hip & Healthy", "https://hipandhealthy.com/category/fitness/feed/"),
    ("Art of Healthy Living", "https://artofhealthyliving.com/category/fitness/feed/"),
    
    # –û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–´–ï + –ü–†–û–§–ò
    ("Born Fitness", "https://www.bornfitness.com/feed/"),
    ("Breaking Muscle", "https://breakingmuscle.com/feed/"),
    ("Muscle & Fitness", "https://www.muscleandfitness.com/feed/"),
    ("BarBend", "https://barbend.com/feed/"),
    
    # –¢–†–ï–ù–î–û–í–´–ï
    ("Daily Burn", "https://dailyburn.com/life/category/fitness/feed"),
]

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
RELEVANT_KEYWORDS = [
    'tabata', 'hiit', 'emom', 'amrap', 'interval', 'circuit', 'workout',
    'home workout', 'bodyweight', 'nutrition', 'meal prep', 'diet',
    'motivation', 'challenge', 'fitness', 'exercise', 'training',
    'strength', 'cardio', 'yoga', 'pilates', 'weight loss', 'health'
]

def test_rss_feed(name, url):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç RSS —Ñ–∏–¥ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"""
    print(f"\n{'='*60}")
    print(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {name}")
    print(f"URL: {url}")
    print(f"{'='*60}")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            print(f"‚ùå –û—à–∏–±–∫–∞: HTTP {response.status_code}")
            return False, None
        
        # –ü–∞—Ä—Å–∏–º XML
        try:
            root = ET.fromstring(response.content)
        except ET.ParseError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
            return False, None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        items = []
        if root.tag.endswith('feed'):  # Atom
            items = root.findall('.//{http://www.w3.org/2005/Atom}entry')
        elif root.tag == 'rss':  # RSS 2.0
            channel = root.find('channel')
            if channel is not None:
                items = channel.findall('item')
        
        if not items:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –≤ —Ñ–∏–¥–µ")
            return False, None
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(items)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç–∞—Ç–µ–π)
        relevant_count = 0
        sample_titles = []
        
        for item in items[:5]:
            title = ''
            description = ''
            
            if item.tag.endswith('entry'):  # Atom
                title_elem = item.find('.//{http://www.w3.org/2005/Atom}title')
                summary_elem = item.find('.//{http://www.w3.org/2005/Atom}summary')
                if title_elem is not None:
                    title = title_elem.text or ''
                if summary_elem is not None:
                    description = summary_elem.text or ''
            else:  # RSS 2.0
                title_elem = item.find('title')
                desc_elem = item.find('description')
                if title_elem is not None:
                    title = title_elem.text or ''
                if desc_elem is not None:
                    description = desc_elem.text or ''
            
            text = (title + ' ' + description).lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            is_relevant = any(keyword in text for keyword in RELEVANT_KEYWORDS)
            
            if is_relevant:
                relevant_count += 1
                sample_titles.append(title[:60])
        
        relevance_percent = (relevant_count / min(5, len(items))) * 100
        print(f"‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevant_count}/{min(5, len(items))} —Å—Ç–∞—Ç–µ–π ({relevance_percent:.0f}%)")
        
        if sample_titles:
            print(f"üìù –ü—Ä–∏–º–µ—Ä—ã —Å—Ç–∞—Ç–µ–π:")
            for t in sample_titles[:3]:
                print(f"   - {t}")
        
        # –°—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º, –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã 40% —Å—Ç–∞—Ç–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
        is_relevant = relevance_percent >= 40
        
        return is_relevant, {
            'name': name,
            'url': url,
            'articles_count': len(items),
            'relevance': relevance_percent
        }
        
    except requests.exceptions.Timeout:
        print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ")
        return False, None
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return False, None
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return False, None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("="*60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï RSS –§–ò–î–û–í –î–õ–Ø –î–ï–í–£–®–ï–ö")
    print("="*60)
    
    working_feeds = []
    failed_feeds = []
    
    for name, url in NEW_RSS_FEEDS:
        is_working, info = test_rss_feed(name, url)
        
        if is_working and info:
            working_feeds.append(info)
        else:
            failed_feeds.append((name, url))
        
        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time.sleep(1)
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "="*60)
    print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("="*60)
    print(f"\n‚úÖ –†–∞–±–æ—á–∏—Ö —Ñ–∏–¥–æ–≤: {len(working_feeds)}")
    print(f"‚ùå –ù–µ —Ä–∞–±–æ—á–∏—Ö —Ñ–∏–¥–æ–≤: {len(failed_feeds)}")
    
    if working_feeds:
        print("\nüìã –†–ê–ë–û–ß–ò–ï –§–ò–î–´ (–¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ø–∞—Ä—Å–µ—Ä):")
        print("\nWOMENSHEALTH_RSS_FEEDS = [")
        for feed in sorted(working_feeds, key=lambda x: x['relevance'], reverse=True):
            print(f"    # {feed['name']} ({feed['relevance']:.0f}% —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å, {feed['articles_count']} —Å—Ç–∞—Ç–µ–π)")
            print(f"    '{feed['url']}',")
        print("]")
    
    if failed_feeds:
        print("\n‚ùå –ù–ï –†–ê–ë–û–¢–ê–Æ–©–ò–ï –§–ò–î–´:")
        for name, url in failed_feeds:
            print(f"   - {name}: {url}")

if __name__ == '__main__':
    main()
